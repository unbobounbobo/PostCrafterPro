"""
Claude 4.5 API service for PostCrafterPro
Based on enhanced_sns_crafter.py with improvements for Tinder UI and Pinecone RAG
"""
import os
import anthropic
import requests
import json
import re
from datetime import datetime
from app.services.prompt_service import PromptService
from pydantic import BaseModel, Field


# Pydantic models for structured output
class PostOption(BaseModel):
    """Single post option"""
    text: str = Field(description="æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆï¼ˆå…¨è§’140å­—/åŠè§’280å­—ä»¥å†…ï¼‰")
    character_count: int = Field(description="æ–‡å­—æ•°")
    is_valid: bool = Field(description="æ–‡å­—æ•°ãŒ280å­—ä»¥å†…ã‹ã©ã†ã‹")


class TwoPostsResponse(BaseModel):
    """Two post options response"""
    post_a: PostOption = Field(description="æŠ•ç¨¿æ¡ˆA")
    post_b: PostOption = Field(description="æŠ•ç¨¿æ¡ˆB")


class ClaudeService:
    """
    Claude 4.5 API integration for SNS post generation
    """

    def __init__(self):
        """Initialize Claude client"""
        api_key = os.getenv('ANTHROPIC_API_KEY')
        if not api_key:
            raise ValueError("ANTHROPIC_API_KEY not found in environment variables")

        self.client = anthropic.Anthropic(api_key=api_key)
        self.model = os.getenv('CLAUDE_MODEL', 'claude-sonnet-4-5-20250929')

        # Tweet length checker API
        self.tweet_checker_api = "https://mj7k0bs0qd.execute-api.ap-northeast-1.amazonaws.com/prod/check"

        # Prompt service for dynamic prompt management
        self.prompt_service = PromptService()

        print(f"[OK] Claude Service initialized with model: {self.model}")

    def create_sns_post_with_context(self, date, decided, url, remarks,
                                     anniversary=None, pinecone_context=None, similar_posts=None,
                                     analytics_insights=None):
        """
        Create initial SNS post with Pinecone context (2 options for Tinder UI)

        Args:
            date: Post date
            decided: Decided content
            url: Product URL
            remarks: Additional remarks
            anniversary: Anniversary information (optional)
            pinecone_context: Product information from Pinecone
            similar_posts: Similar past posts
            analytics_insights: X Analytics performance insights

        Returns:
            dict: {
                'post_a': {'text': str, 'character_count': int, 'is_valid': bool},
                'post_b': {'text': str, 'character_count': int, 'is_valid': bool},
                'metadata': {...}
            }
        """
        # Build message content
        message_content = self._construct_message(
            date, decided, url, remarks, anniversary,
            pinecone_context, similar_posts, analytics_insights,
            request_type='initial'
        )

        # Define tools
        tools = [
            {
                "name": "tweet_length_checker",
                "description": "API to check if a given text meets Twitter's length requirements",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "text": {
                            "type": "string",
                            "description": "The text to be checked for Twitter length requirements"
                        }
                    },
                    "required": ["text"]
                }
            },
            {
                "name": "web_search",
                "type": "web_search_20250305"
            }
        ]

        conversation = [{"role": "user", "content": message_content}]

        # Result container
        result = {
            "post_a": None,
            "post_b": None,
            "metadata": {
                "model": self.model,
                "tokens": {"input": 0, "output": 0}
            }
        }

        try:
            print(f"\n{'ğŸ”µ'*30}")
            print(f"[INFO] Claude API æŠ•ç¨¿ç”Ÿæˆé–‹å§‹")
            print(f"   ãƒ¢ãƒ‡ãƒ«: {self.model}")
            print(f"   æ—¥ä»˜: {date}")
            print(f"   æ±ºå®šäº‹é …: {decided}")
            print(f"{'ğŸ”µ'*30}\n")

            # Conversation loop (max 10 turns)
            max_turns = 10
            current_turn = 0

            while current_turn < max_turns:
                current_turn += 1
                print(f"\n{'='*60}")
                print(f"ä¼šè©±ã‚¿ãƒ¼ãƒ³ {current_turn}/{max_turns}")
                print(f"{'='*60}")

                # Force final output after turn 6
                if current_turn >= 6:
                    print(f"\nâš ï¸  [è­¦å‘Š] ã‚¿ãƒ¼ãƒ³æ•°ãŒ6ã«åˆ°é” - å¼·åˆ¶çš„ã«æœ€çµ‚å‡ºåŠ›ã‚’è¦æ±‚ã—ã¾ã™")
                    conversation.append({
                        "role": "user",
                        "content": "ã“ã‚Œã¾ã§ã®æ¤œè¨ã«åŸºã¥ã„ã¦ã€2ã¤ã®æœ€çµ‚æŠ•ç¨¿æ¡ˆã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
                    })

                    print(f"[INFO] æ§‹é€ åŒ–å‡ºåŠ›ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
                    # Request JSON output via system prompt (Anthropic API doesn't support response_format)
                    final_response = self.client.messages.create(
                        model=self.model,
                        max_tokens=10000,
                        temperature=1,
                        system=self.prompt_service.get_system_prompt('final'),
                        messages=conversation
                    )

                    print(f"[INFO] æ§‹é€ åŒ–å‡ºåŠ›ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡å®Œäº†")
                    # Parse structured output
                    self._parse_structured_output(final_response, result)

                    break

                # Regular API request
                response = self.client.beta.messages.create(
                    model=self.model,
                    max_tokens=16000,
                    temperature=1,
                    system=self.prompt_service.get_system_prompt('initial'),
                    messages=conversation,
                    tools=tools,
                    thinking={"type": "enabled", "budget_tokens": 6554},
                    betas=["web-search-2025-03-05", "output-128k-2025-02-19"]
                )

                # Log web search results if any
                self._log_web_search_results(response)

                # Add response to conversation
                conversation.append({"role": "assistant", "content": response.content})

                # Check if conversation is complete
                if response.stop_reason != "tool_use":
                    print(f"\nâœ… [å®Œäº†] Claudeå¿œç­”å®Œäº† (stop_reason: {response.stop_reason})")
                    print(f"[INFO] æœ€çµ‚æŠ•ç¨¿æ¡ˆã®æ§‹é€ åŒ–å‡ºåŠ›ã‚’è¦æ±‚ã—ã¾ã™")

                    # Request structured output for final posts
                    conversation.append({
                        "role": "user",
                        "content": "2ã¤ã®æŠ•ç¨¿æ¡ˆã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
                    })

                    print(f"[INFO] æ§‹é€ åŒ–å‡ºåŠ›ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
                    final_response = self.client.messages.create(
                        model=self.model,
                        max_tokens=10000,
                        temperature=1,
                        system=self.prompt_service.get_system_prompt('final'),
                        messages=conversation
                    )

                    print(f"[INFO] æ§‹é€ åŒ–å‡ºåŠ›ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡å®Œäº†")
                    print(f"[DEBUG] ãƒ¬ã‚¹ãƒãƒ³ã‚¹è©³ç´°:")
                    print(f"   - stop_reason: {final_response.stop_reason}")
                    print(f"   - content blocks: {len(final_response.content)}")
                    for i, block in enumerate(final_response.content):
                        print(f"   - block[{i}]: type={getattr(block, 'type', 'unknown')}, length={len(getattr(block, 'text', '')) if hasattr(block, 'text') else 0}")
                        if hasattr(block, 'text'):
                            print(f"      preview: {block.text[:200]}...")

                    self._parse_structured_output(final_response, result)
                    break

                # Process tool use
                tool_outputs = self._process_tool_use(response)
                if tool_outputs:
                    conversation.append({"role": "user", "content": tool_outputs})

            print(f"\n{'ğŸ”µ'*30}")
            print(f"[SUCCESS] æŠ•ç¨¿ç”Ÿæˆå®Œäº†")
            print(f"   post_a: {'âœ… ã‚ã‚Š' if result.get('post_a') else 'âŒ ãªã—'}")
            print(f"   post_b: {'âœ… ã‚ã‚Š' if result.get('post_b') else 'âŒ ãªã—'}")
            print(f"{'ğŸ”µ'*30}\n")

            return result

        except Exception as e:
            print(f"\n{'âŒ'*30}")
            print(f"[CRITICAL ERROR] Claude APIå®Ÿè¡Œä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ")
            print(f"ã‚¨ãƒ©ãƒ¼å†…å®¹: {e}")
            print(f"{'âŒ'*30}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}

    def refine_post(self, selected_post, refinement_request=None, round_num=2):
        """
        Refine selected post and generate 2 improved options

        Args:
            selected_post: The post text selected by user
            refinement_request: Optional refinement request
            round_num: Round number

        Returns:
            dict: {
                'post_a': {...},
                'post_b': {...},
                'metadata': {...}
            }
        """
        print(f"\n{'ğŸŸ '*30}")
        print(f"[INFO] æŠ•ç¨¿æ”¹å–„ï¼ˆrefine_postï¼‰é–‹å§‹")
        print(f"   ãƒ¢ãƒ‡ãƒ«: {self.model}")
        print(f"   ãƒ©ã‚¦ãƒ³ãƒ‰: {round_num}")
        print(f"   æ”¹å–„ãƒªã‚¯ã‚¨ã‚¹ãƒˆ: {refinement_request or 'ï¼ˆãªã—ï¼‰'}")
        print(f"   å…ƒã®æŠ•ç¨¿: {selected_post[:100]}...")
        print(f"{'ğŸŸ '*30}\n")

        # Build refinement message from template
        template = self.prompt_service.get_refinement_prompt_template()

        refinement_instruction = f"ã€Œ{refinement_request}ã€ã¨ã„ã†è¦æœ›ã‚’åæ˜ ã—ãŸ" if refinement_request else ""

        message = template.format(
            refinement_instruction=refinement_instruction,
            selected_post=selected_post
        )

        print(f"[INFO] ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ§‹ç¯‰å®Œäº†")
        conversation = [{"role": "user", "content": message}]

        # Define tools (same as initial generation)
        tools = [
            {
                "name": "tweet_length_checker",
                "description": "API to check if a given text meets Twitter's length requirements",
                "input_schema": {
                    "type": "object",
                    "properties": {
                        "text": {
                            "type": "string",
                            "description": "The text to be checked for Twitter length requirements"
                        }
                    },
                    "required": ["text"]
                }
            }
        ]

        # Result container
        result = {
            "post_a": None,
            "post_b": None,
            "metadata": {"model": self.model, "round": round_num}
        }

        try:
            print(f"[INFO] Claude API ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­ï¼ˆãƒ„ãƒ¼ãƒ«ä½¿ç”¨å¯èƒ½ï¼‰...")

            # Conversation loop (max 5 turns for refinement)
            max_turns = 5
            current_turn = 0

            while current_turn < max_turns:
                current_turn += 1
                print(f"\n{'='*60}")
                print(f"æ”¹å–„ã‚¿ãƒ¼ãƒ³ {current_turn}/{max_turns}")
                print(f"{'='*60}")

                # Force final output after turn 3
                if current_turn >= 3:
                    print(f"\nâš ï¸  [è­¦å‘Š] ã‚¿ãƒ¼ãƒ³æ•°ãŒ3ã«åˆ°é” - å¼·åˆ¶çš„ã«æœ€çµ‚å‡ºåŠ›ã‚’è¦æ±‚ã—ã¾ã™")
                    conversation.append({
                        "role": "user",
                        "content": "ã“ã‚Œã¾ã§ã®æ¤œè¨ã«åŸºã¥ã„ã¦ã€2ã¤ã®æ”¹å–„æ¡ˆã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
                    })

                    print(f"[INFO] æ§‹é€ åŒ–å‡ºåŠ›ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
                    final_response = self.client.messages.create(
                        model=self.model,
                        max_tokens=8000,
                        temperature=1,
                        system=self.prompt_service.get_system_prompt('refinement'),
                        messages=conversation
                    )

                    print(f"[INFO] æ§‹é€ åŒ–å‡ºåŠ›ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡å®Œäº†")
                    self._parse_structured_output(final_response, result)
                    break

                # Regular API request with tools
                response = self.client.messages.create(
                    model=self.model,
                    max_tokens=8000,
                    temperature=1,
                    system=self.prompt_service.get_system_prompt('refinement'),
                    messages=conversation,
                    tools=tools
                )

                # Add response to conversation
                conversation.append({"role": "assistant", "content": response.content})

                # Check if conversation is complete
                if response.stop_reason != "tool_use":
                    print(f"\nâœ… [å®Œäº†] Claudeå¿œç­”å®Œäº† (stop_reason: {response.stop_reason})")
                    print(f"[INFO] æœ€çµ‚æ”¹å–„æ¡ˆã®æ§‹é€ åŒ–å‡ºåŠ›ã‚’è¦æ±‚ã—ã¾ã™")

                    # Request structured output for final posts
                    conversation.append({
                        "role": "user",
                        "content": "2ã¤ã®æ”¹å–„æ¡ˆã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚"
                    })

                    print(f"[INFO] æ§‹é€ åŒ–å‡ºåŠ›ãƒªã‚¯ã‚¨ã‚¹ãƒˆé€ä¿¡ä¸­...")
                    final_response = self.client.messages.create(
                        model=self.model,
                        max_tokens=8000,
                        temperature=1,
                        system=self.prompt_service.get_system_prompt('refinement'),
                        messages=conversation
                    )

                    print(f"[INFO] æ§‹é€ åŒ–å‡ºåŠ›ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡å®Œäº†")
                    self._parse_structured_output(final_response, result)
                    break

                # Process tool use
                tool_outputs = self._process_tool_use(response)
                if tool_outputs:
                    conversation.append({"role": "user", "content": tool_outputs})

            print(f"\n{'ğŸŸ '*30}")
            print(f"[SUCCESS] æŠ•ç¨¿æ”¹å–„å®Œäº†")
            print(f"   post_a: {'âœ… ã‚ã‚Š' if result.get('post_a') else 'âŒ ãªã—'}")
            print(f"   post_b: {'âœ… ã‚ã‚Š' if result.get('post_b') else 'âŒ ãªã—'}")
            print(f"{'ğŸŸ '*30}\n")

            return result

        except Exception as e:
            print(f"\n{'âŒ'*30}")
            print(f"[CRITICAL ERROR] æŠ•ç¨¿æ”¹å–„ä¸­ã«ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿ")
            print(f"ã‚¨ãƒ©ãƒ¼å†…å®¹: {e}")
            print(f"{'âŒ'*30}")
            import traceback
            traceback.print_exc()
            return {"error": str(e)}

    def _construct_message(self, date, decided, url, remarks, anniversary,
                          pinecone_context, similar_posts, analytics_insights=None,
                          request_type='initial'):
        """
        Construct message content with Pinecone, past posts, and analytics context

        Args:
            date, decided, url, remarks, anniversary: Post information
            pinecone_context: Product info from Pinecone
            similar_posts: Similar past posts
            analytics_insights: X Analytics performance insights
            request_type: 'initial' or 'refinement'

        Returns:
            str: Formatted message content
        """
        # Pinecone context section
        pinecone_section = ""
        if pinecone_context and pinecone_context.get('combined_summary'):
            pinecone_section = f"""ã€Pineconeæ¤œç´¢çµæœï¼ˆå•†å“æƒ…å ±ï¼‰ã€‘
{pinecone_context['combined_summary']}
"""

        # Similar posts section
        similar_section = ""
        if similar_posts:
            # Check if similar_posts is already a formatted string
            if isinstance(similar_posts, str):
                # Already formatted by format_similar_posts_context()
                similar_section = similar_posts
            else:
                # Process raw list of posts
                similar_texts = []
                for i, post in enumerate(similar_posts[:3], 1):
                    if isinstance(post, dict):
                        post_text = post.get('text', post.get('æœ€çµ‚æŠ•ç¨¿', ''))
                        if post_text:
                            similar_texts.append(f"{i}. {post_text}")

                if similar_texts:
                    similar_section = f"""ã€éå»ã®é¡ä¼¼æŠ•ç¨¿ã€‘
{chr(10).join(similar_texts)}
"""

        # X Analytics insights section (NEW)
        analytics_section = ""
        if analytics_insights:
            analytics_section = f"""{analytics_insights}

"""

        # Anniversary line
        anniversary_line = f"è¨˜å¿µæ—¥: {anniversary}\n" if anniversary else ""

        # Get prompt template from prompt service
        template = self.prompt_service.get_user_prompt_template()

        # Format template with variables
        prompt = template.format(
            date=date,
            decided=decided,
            url=url,
            anniversary_line=anniversary_line,
            remarks=remarks,
            pinecone_section=pinecone_section,
            similar_section=similar_section,
            analytics_section=analytics_section
        )

        return prompt

    def _parse_structured_output(self, response, result):
        """
        Parse structured JSON output from Claude's response

        Args:
            response: Claude API response with structured output
            result: Result dictionary to populate
        """
        print(f"\n{'='*60}")
        print(f"[DEBUG] _parse_structured_output() é–‹å§‹")
        print(f"[DEBUG] ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãƒ–ãƒ­ãƒƒã‚¯æ•°: {len(response.content)}")
        print(f"{'='*60}")

        try:
            # Get the JSON content from response
            for i, block in enumerate(response.content):
                block_type = getattr(block, 'type', 'unknown')
                print(f"\n[DEBUG] ãƒ–ãƒ­ãƒƒã‚¯{i}: type={block_type}")

                if hasattr(block, 'type') and block.type == 'text':
                    block_text = block.text
                    print(f"[DEBUG] ãƒ†ã‚­ã‚¹ãƒˆãƒ–ãƒ­ãƒƒã‚¯ç™ºè¦‹ (é•·ã•: {len(block_text)}æ–‡å­—)")
                    print(f"[DEBUG] ãƒ†ã‚­ã‚¹ãƒˆå†…å®¹ï¼ˆæœ€åˆã®500æ–‡å­—ï¼‰:")
                    print(f"{block_text[:500]}")
                    print(f"[DEBUG] ---")

                    # Extract JSON from code blocks if present
                    print(f"[DEBUG] JSONæŠ½å‡ºå‡¦ç†é–‹å§‹...")
                    json_text = self._extract_json_from_text(block_text)
                    print(f"[DEBUG] æŠ½å‡ºã•ã‚ŒãŸJSON (é•·ã•: {len(json_text)}æ–‡å­—):")
                    print(f"{json_text[:500]}")
                    print(f"[DEBUG] ---")

                    try:
                        json_data = json.loads(json_text)
                        print(f"[DEBUG] JSON ãƒ‘ãƒ¼ã‚¹æˆåŠŸï¼")
                        print(f"[DEBUG] JSONã‚­ãƒ¼: {list(json_data.keys())}")

                        # Parse post_a
                        if 'post_a' in json_data:
                            post_a = json_data['post_a']
                            print(f"[DEBUG] post_a ãƒ‡ãƒ¼ã‚¿: {post_a}")

                            # Remove markdown formatting
                            text_a = self._clean_text(post_a['text'])
                            result['post_a'] = {
                                'text': text_a,
                                'character_count': len(text_a),
                                'is_valid': len(text_a) <= 280
                            }
                            print(f"âœ… [æ¡ˆAå–å¾—æˆåŠŸ] {len(text_a)}æ–‡å­—")
                            print(f"   å†…å®¹: {text_a[:100]}...")
                        else:
                            print(f"âš ï¸  [è­¦å‘Š] post_a ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                        # Parse post_b
                        if 'post_b' in json_data:
                            post_b = json_data['post_b']
                            print(f"[DEBUG] post_b ãƒ‡ãƒ¼ã‚¿: {post_b}")

                            # Remove markdown formatting
                            text_b = self._clean_text(post_b['text'])
                            result['post_b'] = {
                                'text': text_b,
                                'character_count': len(text_b),
                                'is_valid': len(text_b) <= 280
                            }
                            print(f"âœ… [æ¡ˆBå–å¾—æˆåŠŸ] {len(text_b)}æ–‡å­—")
                            print(f"   å†…å®¹: {text_b[:100]}...")
                        else:
                            print(f"âš ï¸  [è­¦å‘Š] post_b ã‚­ãƒ¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

                        break

                    except json.JSONDecodeError as json_err:
                        print(f"âŒ [ã‚¨ãƒ©ãƒ¼] JSON ãƒ‘ãƒ¼ã‚¹å¤±æ•—: {json_err}")
                        print(f"[DEBUG] ãƒ‘ãƒ¼ã‚¹å¤±æ•—ã—ãŸãƒ†ã‚­ã‚¹ãƒˆ: {block_text[:500]}...")
                        print(f"[INFO] ãƒ¬ã‚¬ã‚·ãƒ¼æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ä¸­...")
                        self._extract_two_posts_legacy(block_text, result)
                        break

                elif hasattr(block, 'type'):
                    print(f"[DEBUG] ãƒ–ãƒ­ãƒƒã‚¯ã‚¿ã‚¤ãƒ— '{block_type}' ã¯ãƒ†ã‚­ã‚¹ãƒˆã§ã¯ã‚ã‚Šã¾ã›ã‚“")

        except json.JSONDecodeError as e:
            print(f"\nâŒ [JSON DECODE ERROR] {e}")
            print(f"[INFO] ãƒ¬ã‚¬ã‚·ãƒ¼æŠ½å‡ºãƒ¡ã‚½ãƒƒãƒ‰ã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯")
            # Fallback to text extraction if JSON fails
            for block in response.content:
                if hasattr(block, 'type') and block.type == 'text':
                    print(f"[DEBUG] ãƒ¬ã‚¬ã‚·ãƒ¼æŠ½å‡ºã‚’å®Ÿè¡Œ: {block.text[:200]}...")
                    self._extract_two_posts_legacy(block.text, result)
                    break
        except Exception as e:
            print(f"\nâŒ [CRITICAL ERROR] äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()

        finally:
            print(f"\n{'='*60}")
            print(f"[DEBUG] _parse_structured_output() çµ‚äº†")
            print(f"[DEBUG] æœ€çµ‚çµæœ:")
            print(f"   post_a: {'ã‚ã‚Š' if result.get('post_a') else 'ãªã—'}")
            print(f"   post_b: {'ã‚ã‚Š' if result.get('post_b') else 'ãªã—'}")
            if result.get('post_a'):
                print(f"   post_a æ–‡å­—æ•°: {result['post_a'].get('character_count', 0)}")
            if result.get('post_b'):
                print(f"   post_b æ–‡å­—æ•°: {result['post_b'].get('character_count', 0)}")
            print(f"{'='*60}\n")

    def _clean_text(self, text):
        """
        Remove markdown formatting from text

        Args:
            text: Text with potential markdown

        Returns:
            str: Cleaned text
        """
        # Remove **bold**
        text = re.sub(r'\*\*(.*?)\*\*', r'\1', text)
        # Remove *italic*
        text = re.sub(r'\*(.*?)\*', r'\1', text)
        return text.strip()

    def _extract_json_from_text(self, text):
        """
        Extract JSON from text, handling code blocks like ```json ... ```

        Args:
            text: Text that may contain JSON or JSON in code blocks

        Returns:
            str: Extracted JSON text with fixed control characters
        """
        extracted_json = None

        # Try to extract from ```json ... ``` code block (more flexible regex)
        # Matches: ```json\n{...}\n``` or ```json\n{...}``` or ```json{...}```
        json_match = re.search(r'```json\s*(.*?)```', text, re.DOTALL)
        if json_match:
            print(f"[DEBUG] JSONã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰æŠ½å‡º")
            extracted_json = json_match.group(1).strip()

        # Try to extract from ``` ... ``` code block without json keyword
        if not extracted_json:
            code_match = re.search(r'```\s*(.*?)```', text, re.DOTALL)
            if code_match:
                potential_json = code_match.group(1).strip()
                # Check if it starts with { or [
                if potential_json.startswith('{') or potential_json.startswith('['):
                    print(f"[DEBUG] æ±ç”¨ã‚³ãƒ¼ãƒ‰ãƒ–ãƒ­ãƒƒã‚¯ã‹ã‚‰JSONæŠ½å‡º")
                    extracted_json = potential_json

        # Try to find JSON object directly (as fallback)
        if not extracted_json:
            json_direct = re.search(r'\{.*\}', text, re.DOTALL)
            if json_direct:
                print(f"[DEBUG] ãƒ†ã‚­ã‚¹ãƒˆå†…ã‹ã‚‰ç›´æ¥JSONæŠ½å‡º")
                extracted_json = json_direct.group(0)

        # No JSON found, return as is (will likely fail JSON parsing)
        if not extracted_json:
            print(f"[WARNING] JSONãŒè¦‹ã¤ã‹ã‚‰ãªã„ã€å…ƒã®ãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”ã™")
            return text.strip()

        # Fix control characters in JSON (newlines, tabs, etc.)
        print(f"[DEBUG] JSONåˆ¶å¾¡æ–‡å­—ã®ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†é–‹å§‹...")
        fixed_json = self._fix_json_control_chars(extracted_json)
        print(f"[DEBUG] ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—å‡¦ç†å®Œäº†")

        return fixed_json

    def _fix_json_control_chars(self, json_text):
        """
        Fix unescaped control characters in JSON string values

        Claude sometimes returns JSON with raw newlines in text values,
        which causes JSON parsing to fail. This method escapes those.

        Args:
            json_text: JSON text with potential unescaped control chars

        Returns:
            str: Fixed JSON text with properly escaped control characters
        """
        def escape_text_value(match):
            """Escape control characters in "text": "..." values"""
            prefix = match.group(1)   # "text": "
            content = match.group(2)  # The actual text content (may have newlines)
            suffix = match.group(3)   # "

            # Escape control characters in the correct order
            # (backslash first to avoid double-escaping)
            if '\\' not in content or '\n' in content or '\r' in content:
                # Only escape if there are actual control chars to escape
                content = content.replace('\\', '\\\\')  # Escape existing backslashes
                content = content.replace('\n', '\\n')   # Escape newlines
                content = content.replace('\r', '\\r')   # Escape carriage returns
                content = content.replace('\t', '\\t')   # Escape tabs
                print(f"[DEBUG] åˆ¶å¾¡æ–‡å­—ã‚’ã‚¨ã‚¹ã‚±ãƒ¼ãƒ—ã—ã¾ã—ãŸ ({len(content)}æ–‡å­—)")

            return prefix + content + suffix

        # Pattern to match: "text" : " ... " (with any whitespace, capturing content)
        # Group 1: "text": "
        # Group 2: content (can include newlines with re.DOTALL)
        # Group 3: " (followed by comma or closing brace)
        pattern = r'("text"\s*:\s*")(.*?)("\s*[,}])'

        fixed = re.sub(pattern, escape_text_value, json_text, flags=re.DOTALL)

        return fixed

    def _extract_two_posts_legacy(self, text, result):
        """
        Legacy method: Extract two post options from Claude's response using regex
        Used as fallback if structured output fails

        Args:
            text: Response text
            result: Result dictionary to populate
        """
        # Extract æ¡ˆA
        match_a = re.search(r'\[æ¡ˆA\](.*?)(?=\[æ¡ˆB\]|\[|$)', text, re.DOTALL)
        if match_a:
            post_a_text = self._clean_text(match_a.group(1))
            result['post_a'] = {
                'text': post_a_text,
                'character_count': len(post_a_text),
                'is_valid': len(post_a_text) <= 280
            }
            print(f"\n[æ¡ˆAæŠ½å‡º(ãƒ¬ã‚¬ã‚·ãƒ¼)] {len(post_a_text)}æ–‡å­—")

        # Extract æ¡ˆB
        match_b = re.search(r'\[æ¡ˆB\](.*?)(?=\[|$)', text, re.DOTALL)
        if match_b:
            post_b_text = self._clean_text(match_b.group(1))
            result['post_b'] = {
                'text': post_b_text,
                'character_count': len(post_b_text),
                'is_valid': len(post_b_text) <= 280
            }
            print(f"[æ¡ˆBæŠ½å‡º(ãƒ¬ã‚¬ã‚·ãƒ¼)] {len(post_b_text)}æ–‡å­—")

    def _log_web_search_results(self, response):
        """
        Log web search results from Claude's response

        Args:
            response: Claude API response
        """
        try:
            for block in response.content:
                # Check for web search tool use
                if hasattr(block, 'type') and block.type == 'tool_use':
                    if hasattr(block, 'name') and block.name == 'web_search':
                        print(f"\n[WEB] Web Searchå®Ÿè¡Œ:")
                        if hasattr(block, 'input') and 'query' in block.input:
                            print(f"   æ¤œç´¢ã‚¯ã‚¨ãƒª: {block.input['query']}")

                # Check for search results in content
                if hasattr(block, 'type') and block.type == 'tool_result':
                    if hasattr(block, 'content'):
                        try:
                            # Try to parse tool result
                            content_str = str(block.content)
                            if 'url' in content_str.lower() or 'http' in content_str:
                                print(f"   å–å¾—å…ƒ: {content_str[:200]}...")
                        except:
                            pass

        except Exception as e:
            # Silent fail - logging is optional
            pass

    def _process_tool_use(self, response):
        """
        Process tool use in Claude's response

        Args:
            response: Claude API response

        Returns:
            list: Tool results to send back to Claude
        """
        tool_outputs = []

        for block in response.content:
            if hasattr(block, 'type') and block.type == 'tool_use':
                print(f"ãƒ„ãƒ¼ãƒ«ä½¿ç”¨æ¤œå‡º: {block.name}")

                if block.name == 'tweet_length_checker':
                    text = block.input.get('text', '')

                    try:
                        api_response = requests.post(
                            self.tweet_checker_api,
                            json={"text": text},
                            timeout=10
                        )

                        if api_response.status_code == 200:
                            api_result = api_response.json()
                            print(f"æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯çµæœ: {api_result}")

                            tool_outputs.append({
                                'type': 'tool_result',
                                'tool_use_id': block.id,
                                'content': json.dumps(api_result)
                            })
                        else:
                            # Fallback
                            char_count = len(text)
                            is_valid = char_count <= 280

                            tool_outputs.append({
                                'type': 'tool_result',
                                'tool_use_id': block.id,
                                'content': json.dumps({
                                    "character_count": char_count,
                                    "is_valid": is_valid
                                })
                            })

                    except Exception as e:
                        print(f"æ–‡å­—æ•°ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {e}")
                        # Fallback
                        char_count = len(text)
                        tool_outputs.append({
                            'type': 'tool_result',
                            'tool_use_id': block.id,
                            'content': json.dumps({
                                "character_count": char_count,
                                "is_valid": char_count <= 280,
                                "error": str(e)
                            })
                        })

        return tool_outputs

    def refine_emojis(self, original_text, emoji_guidelines):
        """
        Refine emoji usage in post based on X Analytics performance data

        Args:
            original_text: Original post text
            emoji_guidelines: Emoji guidelines from AnalyticsService.get_emoji_guidelines()

        Returns:
            dict: {
                'original': str,
                'improved': str,
                'changes': [{'from': 'ğŸ’™', 'to': 'ğŸš¨', 'reason': '...'}],
                'character_count': int,
                'is_valid': bool
            }
        """
        print(f"\n[INFO] çµµæ–‡å­—æ”¹å–„ãƒ—ãƒ­ã‚»ã‚¹é–‹å§‹...")
        print(f"   å…ƒãƒ†ã‚­ã‚¹ãƒˆé•·: {len(original_text)}æ–‡å­—")

        # Build prompt with guidelines
        guidelines_text = emoji_guidelines.get('guidelines_text', '')

        system_prompt = f"""ã‚ãªãŸã¯Xï¼ˆæ—§Twitterï¼‰ã®çµµæ–‡å­—æœ€é©åŒ–ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆã§ã™ã€‚

{guidelines_text}

ã€ã‚¿ã‚¹ã‚¯ã€‘
ä¸ãˆã‚‰ã‚ŒãŸæŠ•ç¨¿ã®çµµæ–‡å­—ã‚’ã€X Analyticsã®å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦æœ€é©åŒ–ã—ã¦ãã ã•ã„ã€‚

ã€ãƒ«ãƒ¼ãƒ«ã€‘
1. æŠ•ç¨¿ã®**æ„å‘³ã‚„æ–‡è„ˆã¯å¤‰ãˆãªã„**ï¼ˆçµµæ–‡å­—ã®ã¿å¤‰æ›´ï¼‰
2. 1æŠ•ç¨¿ã‚ãŸã‚Šçµµæ–‡å­—ã¯2-4å€‹ã¾ã§
3. é«˜ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆçµµæ–‡å­—ã«ç½®ãæ›ãˆã‚‹
4. ä½ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆçµµæ–‡å­—ã¯å‰Šé™¤ã¾ãŸã¯ç½®ãæ›ãˆ
5. çµµæ–‡å­—ã¯æ–‡è„ˆã«è‡ªç„¶ã«æº¶ã‘è¾¼ã‚€ã‚ˆã†ã«é…ç½®
6. æ–‡å­—æ•°åˆ¶é™ï¼ˆ280æ–‡å­—ï¼‰ã‚’è¶…ãˆãªã„ã‚ˆã†ã«ã™ã‚‹

ã€å‡ºåŠ›å½¢å¼ã€‘
JSONã§ä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›:
{{
  "improved_text": "æ”¹å–„å¾Œã®æŠ•ç¨¿ãƒ†ã‚­ã‚¹ãƒˆ",
  "changes": [
    {{"from": "å…ƒã®çµµæ–‡å­—", "to": "æ–°ã—ã„çµµæ–‡å­—", "reason": "å¤‰æ›´ç†ç”±"}}
  ],
  "reasoning": "æ”¹å–„ã®æ„å›³ã¨æœŸå¾…ã•ã‚Œã‚‹åŠ¹æœ"
}}"""

        user_message = f"""ä»¥ä¸‹ã®æŠ•ç¨¿ã®çµµæ–‡å­—ã‚’æœ€é©åŒ–ã—ã¦ãã ã•ã„ï¼š

ã€å…ƒã®æŠ•ç¨¿ã€‘
{original_text}

X Analyticsãƒ‡ãƒ¼ã‚¿ã«åŸºã¥ã„ã¦ã€ã‚¨ãƒ³ã‚²ãƒ¼ã‚¸ãƒ¡ãƒ³ãƒˆç‡ãŒé«˜ã¾ã‚‹ã‚ˆã†ã«çµµæ–‡å­—ã‚’æ”¹å–„ã—ã¦ãã ã•ã„ã€‚"""

        try:
            # Call Claude API
            response = self.client.messages.create(
                model=self.model,
                max_tokens=4000,
                temperature=0.7,
                system=system_prompt,
                messages=[{"role": "user", "content": user_message}]
            )

            # Parse response
            result_text = ""
            for block in response.content:
                if block.type == "text":
                    result_text += block.text

            print(f"[DEBUG] Claudeå¿œç­”: {result_text[:200]}...")

            # Extract JSON
            json_match = re.search(r'\{[\s\S]*"improved_text"[\s\S]*\}', result_text)
            if json_match:
                result_json = json.loads(json_match.group())

                improved_text = result_json.get('improved_text', original_text)
                changes = result_json.get('changes', [])
                reasoning = result_json.get('reasoning', '')

                # Check character count with tweet_length_checker
                char_count, is_valid = self._check_tweet_length(improved_text)

                print(f"[OK] çµµæ–‡å­—æ”¹å–„å®Œäº†")
                print(f"   æ”¹å–„å¾Œæ–‡å­—æ•°: {char_count}æ–‡å­—")
                print(f"   å¤‰æ›´ç®‡æ‰€: {len(changes)}ä»¶")

                return {
                    'original': original_text,
                    'improved': improved_text,
                    'changes': changes,
                    'reasoning': reasoning,
                    'character_count': char_count,
                    'is_valid': is_valid
                }

            else:
                print(f"[WARN]  JSONæŠ½å‡ºå¤±æ•—ã€å…ƒãƒ†ã‚­ã‚¹ãƒˆã‚’è¿”å´")
                char_count, is_valid = self._check_tweet_length(original_text)
                return {
                    'original': original_text,
                    'improved': original_text,
                    'changes': [],
                    'reasoning': 'JSONè§£æã«å¤±æ•—ã—ã¾ã—ãŸ',
                    'character_count': char_count,
                    'is_valid': is_valid
                }

        except Exception as e:
            print(f"[ERROR] çµµæ–‡å­—æ”¹å–„ã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()

            char_count, is_valid = self._check_tweet_length(original_text)
            return {
                'original': original_text,
                'improved': original_text,
                'changes': [],
                'reasoning': f'ã‚¨ãƒ©ãƒ¼: {str(e)}',
                'character_count': char_count,
                'is_valid': is_valid,
                'error': str(e)
            }

    def _check_tweet_length(self, text):
        """
        Check tweet length using tweet_length_checker API

        Args:
            text: Text to check

        Returns:
            tuple: (character_count, is_valid)
        """
        try:
            response = requests.post(
                self.tweet_checker_url,
                json={"text": text},
                timeout=10
            )
            data = response.json()
            return data.get('weightedLength', len(text)), data.get('isValid', len(text) <= 280)
        except Exception as e:
            print(f"[WARN] Tweet length check failed: {e}")
            return len(text), len(text) <= 280
